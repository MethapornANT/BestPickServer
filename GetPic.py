import asyncio
import os
import shutil
import hashlib
from aiohttp import ClientSession, ClientTimeout
from urllib.parse import urlparse, urlencode
from playwright.async_api import async_playwright
import time

# ================== CONFIG =====================
DATA_FOLDER = "data"                # ‡πÇ‡∏ü‡∏•‡πÄ‡∏î‡∏≠‡∏£‡πå‡∏´‡∏•‡∏±‡∏Å‡πÄ‡∏Å‡πá‡∏ö‡∏£‡∏π‡∏õ
TIMEOUT_DURATION = 7                    # timeout ‡∏ï‡πà‡∏≠ request (‡∏ß‡∏¥‡∏ô‡∏≤‡∏ó‡∏µ)
CLEAR_FOLDER_BEFORE_RUN = True          # True = ‡∏•‡∏ö‡πÑ‡∏ü‡∏•‡πå‡∏†‡∏≤‡∏û‡πÄ‡∏Å‡πà‡∏≤‡∏ó‡∏±‡πâ‡∏á‡∏´‡∏°‡∏î‡∏Å‡πà‡∏≠‡∏ô‡∏£‡∏±‡∏ô, False = ‡πÇ‡∏´‡∏•‡∏î‡∏ï‡πà‡∏≠‡∏à‡∏≤‡∏Å‡πÄ‡∏î‡∏¥‡∏°
HEADLESS_BROWSER = True                # False = ‡πÄ‡∏õ‡∏¥‡∏î browser ‡πÉ‡∏´‡πâ‡πÄ‡∏´‡πá‡∏ô, True = ‡∏ã‡πà‡∏≠‡∏ô browser
CATEGORY_SEARCHES = {
    "anime": ["anime", "anime girl", "anime boy", "anime love", "anime kiss", "cartoon charater", "anime AI", "anime cute", "anime beautiful"],
    "hentai": ["hentai", "hentai girl", "hentai boy", "hentai nude", "cartoon porn", "hentai fuck", "hentai cute", "hentai beautiful"],
    "normal": ["boy", "girl", "women", "man", "cat" , "nature", "athlete", "footballer", "dog", "animal"],
    "porn": ["porn xxx", "nude porn", "pussy xxx", "cock xxx", "gay porn", "sex porn", "hardcore porn", "adult porn", "lesbian porn"],
    "sexy": ["bikini girl", "sexy girl", "bikini women", "sexy", "sexy man", "cartoon sexy", "underwear sexy", "hot girl", "lingeries", "no bra sexy"]
}
MAX_IMAGES_PER_CATEGORY = 3000          # ‡∏à‡∏≥‡∏ô‡∏ß‡∏ô‡∏£‡∏π‡∏õ‡∏ï‡πà‡∏≠‡∏´‡∏°‡∏ß‡∏î‡∏´‡∏°‡∏π‡πà
MAX_RELATED_DEPTH = 3                   # ‡πÄ‡∏û‡∏¥‡πà‡∏°‡∏Ñ‡∏ß‡∏≤‡∏°‡∏•‡∏∂‡∏Å‡∏Ç‡∏≠‡∏á related search
BATCH_SIZE = 30                         # ‡πÇ‡∏´‡∏•‡∏î‡∏£‡∏π‡∏õ‡∏û‡∏£‡πâ‡∏≠‡∏°‡∏Å‡∏±‡∏ô‡∏Å‡∏µ‡πà‡∏£‡∏π‡∏õ (‡πÄ‡∏û‡∏¥‡πà‡∏°‡∏Ñ‡∏ß‡∏≤‡∏°‡πÄ‡∏£‡πá‡∏ß)
# ===============================================

def calculate_image_hash(image_data: bytes) -> str:
    return hashlib.md5(image_data).hexdigest()

def clear_all_category_images():
    for category in CATEGORY_SEARCHES:
        folder_path = os.path.join(DATA_FOLDER, category)
        if os.path.exists(folder_path):
            for filename in os.listdir(folder_path):
                file_path = os.path.join(folder_path, filename)
                if os.path.isfile(file_path):
                    os.remove(file_path)
            print(f"‡∏•‡∏ö‡πÑ‡∏ü‡∏•‡πå‡∏†‡∏≤‡∏û‡∏ó‡∏±‡πâ‡∏á‡∏´‡∏°‡∏î‡πÉ‡∏ô: {folder_path}")

def ensure_folder_exists(folder_path: str):
    if not os.path.exists(folder_path):
        os.makedirs(folder_path)
        print(f"‡∏™‡∏£‡πâ‡∏≤‡∏á‡πÇ‡∏ü‡∏•‡πÄ‡∏î‡∏≠‡∏£‡πå: {folder_path}")

def count_actual_files_in_folder(folder_path):
    """‡∏ô‡∏±‡∏ö‡πÑ‡∏ü‡∏•‡πå‡∏à‡∏£‡∏¥‡∏á‡πÉ‡∏ô‡πÇ‡∏ü‡∏•‡πÄ‡∏î‡∏≠‡∏£‡πå"""
    if not os.path.exists(folder_path):
        return 0
    
    image_extensions = {'.jpg', '.jpeg', '.png', '.gif', '.bmp', '.webp'}
    count = 0
    
    for file in os.listdir(folder_path):
        file_path = os.path.join(folder_path, file)
        if os.path.isfile(file_path):
            file_ext = os.path.splitext(file)[1].lower()
            if file_ext in image_extensions and os.path.getsize(file_path) > 1000:
                count += 1
    
    return count

def get_image_summary():
    """‡∏™‡∏£‡∏∏‡∏õ‡∏à‡∏≥‡∏ô‡∏ß‡∏ô‡∏†‡∏≤‡∏û‡πÉ‡∏ô‡πÅ‡∏ï‡πà‡∏•‡∏∞‡πÇ‡∏ü‡∏•‡πÄ‡∏î‡∏≠‡∏£‡πå"""
    picdata_path = "PicData"
    if not os.path.exists(picdata_path):
        return {}
    
    summary = {}
    categories = ["anime", "hentai", "normal", "porn", "sexy"]
    
    for category in categories:
        category_path = os.path.join(picdata_path, category)
        count = count_actual_files_in_folder(category_path)
        summary[category] = count
    
    return summary

def clean_corrupted_images():
    """‡∏•‡∏ö‡πÑ‡∏ü‡∏•‡πå‡∏†‡∏≤‡∏û‡πÄ‡∏™‡∏µ‡∏¢"""
    picdata_path = "PicData"
    if not os.path.exists(picdata_path):
        return 0
    
    cleaned_count = 0
    categories = ["anime", "hentai", "normal", "porn", "sexy"]
    
    for category in categories:
        category_path = os.path.join(picdata_path, category)
        if not os.path.exists(category_path):
            continue
        
        image_extensions = {'.jpg', '.jpeg', '.png', '.gif', '.bmp', '.webp'}
        for file in os.listdir(category_path):
            file_path = os.path.join(category_path, file)
            if os.path.isfile(file_path):
                file_ext = os.path.splitext(file)[1].lower()
                if file_ext in image_extensions:
                    try:
                        file_size = os.path.getsize(file_path)
                        if file_size < 1000:  # ‡πÑ‡∏ü‡∏•‡πå‡πÄ‡∏™‡∏µ‡∏¢ (‡∏ô‡πâ‡∏≠‡∏¢‡∏Å‡∏ß‡πà‡∏≤ 1KB)
                            os.remove(file_path)
                            cleaned_count += 1
                    except:
                        pass
    
    return cleaned_count

async def disable_safesearch(page):
    try:
        safesearch_btn = await page.query_selector('div[aria-pressed][role="button"]:has-text("‡∏õ‡∏¥‡∏î‡∏≠‡∏¢‡∏π‡πà")')
        if safesearch_btn:
            print("‡∏û‡∏ö SafeSearch: ‡∏õ‡∏¥‡∏î‡∏≠‡∏¢‡∏π‡πà ‚Üí ‡∏Å‡∏≥‡∏•‡∏±‡∏á‡∏õ‡∏¥‡∏î...")
            await safesearch_btn.click()
            await asyncio.sleep(1)
            await page.reload()
            print("‡∏õ‡∏¥‡∏î SafeSearch ‡∏™‡∏≥‡πÄ‡∏£‡πá‡∏à ‡∏£‡∏µ‡πÄ‡∏ü‡∏£‡∏ä‡∏´‡∏ô‡πâ‡∏≤‡πÅ‡∏•‡πâ‡∏ß")
            return True
    except Exception:
        pass
    return False

def print_progress_bar(current, total, query, bar_length=30):
    percent = current / total if total else 0
    bar = '#' * int(bar_length * percent) + '-' * (bar_length - int(bar_length * percent))
    print(f"\r[{bar}] {percent*100:.1f}% ({current}/{total}) | {query}", end='', flush=True)

async def get_related_searches(page):
    related = set()
    try:
        elements = await page.query_selector_all('a[aria-label^="‡∏Ñ‡πâ‡∏ô‡∏´‡∏≤‡πÄ‡∏û‡∏¥‡πà‡∏°‡πÄ‡∏ï‡∏¥‡∏°‡πÄ‡∏Å‡∏µ‡πà‡∏¢‡∏ß‡∏Å‡∏±‡∏ö"]')
        for el in elements:
            text = await el.inner_text()
            if text:
                related.add(text.strip())
        if not related:
            related_box = await page.query_selector('div:has(h2:has-text("‡∏Å‡∏≤‡∏£‡∏Ñ‡πâ‡∏ô‡∏´‡∏≤‡∏ó‡∏µ‡πà‡πÄ‡∏Å‡∏µ‡πà‡∏¢‡∏ß‡∏Ç‡πâ‡∏≠‡∏á"))')
            if related_box:
                links = await related_box.query_selector_all('a')
                for link in links:
                    text = await link.inner_text()
                    if text:
                        related.add(text.strip())
    except Exception:
        pass
    return list(related)

async def click_last_related_search(page):
    try:
        related_box = await page.query_selector('div:has(h2:has-text("‡∏Å‡∏≤‡∏£‡∏Ñ‡πâ‡∏ô‡∏´‡∏≤‡∏ó‡∏µ‡πà‡πÄ‡∏Å‡∏µ‡πà‡∏¢‡∏ß‡∏Ç‡πâ‡∏≠‡∏á"))')
        if related_box:
            links = await related_box.query_selector_all('a')
            if links:
                await links[-1].click()
                await asyncio.sleep(0.5)
                return True
    except Exception:
        pass
    return False

async def click_load_more(page):
    # ‡∏ü‡∏±‡∏á‡∏Å‡πå‡∏ä‡∏±‡∏ô‡∏ô‡∏µ‡πâ‡∏à‡∏∞‡πÄ‡∏•‡∏∑‡πà‡∏≠‡∏ô‡∏•‡∏á‡πÑ‡∏õ‡∏¢‡∏±‡∏á‡∏†‡∏≤‡∏û‡∏™‡∏∏‡∏î‡∏ó‡πâ‡∏≤‡∏¢ ‡πÅ‡∏•‡πâ‡∏ß‡∏´‡∏≤‡πÅ‡∏•‡∏∞‡∏Ñ‡∏•‡∏¥‡∏Å‡∏õ‡∏∏‡πà‡∏° '‡∏î‡∏π‡πÄ‡∏û‡∏¥‡πà‡∏°‡πÄ‡∏ï‡∏¥‡∏°' (‡∏ñ‡πâ‡∏≤‡∏°‡∏µ)
    try:
        # ‡πÄ‡∏•‡∏∑‡πà‡∏≠‡∏ô‡∏•‡∏á‡πÑ‡∏õ‡∏¢‡∏±‡∏á‡∏†‡∏≤‡∏û‡∏™‡∏∏‡∏î‡∏ó‡πâ‡∏≤‡∏¢ (‡∏ù‡∏±‡πà‡∏á‡∏Ç‡∏ß‡∏≤)
        await page.evaluate('window.scrollTo(0, document.body.scrollHeight)')
        await asyncio.sleep(0.3)
        # ‡∏´‡∏≤‡πÇ‡∏î‡∏¢‡∏Ç‡πâ‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏°
        btn = await page.query_selector('div:has-text("‡∏î‡∏π‡πÄ‡∏û‡∏¥‡πà‡∏°‡πÄ‡∏ï‡∏¥‡∏°")')
        if not btn:
            # ‡∏´‡∏≤‡πÇ‡∏î‡∏¢ class (‡πÄ‡∏ä‡πà‡∏ô CCYCud)
            btn = await page.query_selector('div.CCYCud')
        if btn:
            await btn.click()
            await asyncio.sleep(0.5)
            return True
    except Exception:
        pass
    return False

async def click_load_more_in_right_panel(page):
    try:
        # scroll panel ‡∏î‡πâ‡∏≤‡∏ô‡∏Ç‡∏ß‡∏≤‡∏•‡∏á‡∏™‡∏∏‡∏î (selector ‡πÉ‡∏´‡∏°‡πà)
        panel = await page.query_selector('div.BIB1wf.ElehLd.fHE6De.Emjfj d')
        used_selector = 'div.BIB1wf.ElehLd.fHE6De.Emjfj d'
        if not panel:
            # fallback selector ‡πÄ‡∏î‡∏¥‡∏°
            panel = await page.query_selector('div.hh1Ztf.ip4nvd.k4o2Hc')
            used_selector = 'div.hh1Ztf.ip4nvd.k4o2Hc'
        if panel:
            print(f'  [LOG] scroll panel ‡∏Ç‡∏ß‡∏≤‡∏î‡πâ‡∏ß‡∏¢ selector: {used_selector}')
            await page.evaluate('(el) => { el.scrollTop = el.scrollHeight }', panel)
            await asyncio.sleep(0.7)
            # ‡∏´‡∏≤‡πÅ‡∏•‡∏∞‡∏Ñ‡∏•‡∏¥‡∏Å‡∏õ‡∏∏‡πà‡∏° '‡∏î‡∏π‡πÄ‡∏û‡∏¥‡πà‡∏°‡πÄ‡∏ï‡∏¥‡∏°' ‡πÉ‡∏ô panel ‡∏î‡πâ‡∏≤‡∏ô‡∏Ç‡∏ß‡∏≤
            btn = await page.query_selector('div.CCYCud, div.CCYCud.A7KIJf')
            if btn:
                print('  [LOG] ‚û°Ô∏è ‡πÄ‡∏à‡∏≠‡∏õ‡∏∏‡πà‡∏° "‡∏î‡∏π‡πÄ‡∏û‡∏¥‡πà‡∏°‡πÄ‡∏ï‡∏¥‡∏°" ‡πÉ‡∏ô panel ‡∏î‡πâ‡∏≤‡∏ô‡∏Ç‡∏ß‡∏≤ ‡∏Å‡∏≥‡∏•‡∏±‡∏á‡∏Å‡∏î...')
                await btn.click()
                await asyncio.sleep(1.2)
                return True
            else:
                print('  [LOG] ‚ùó ‡πÑ‡∏°‡πà‡πÄ‡∏à‡∏≠‡∏õ‡∏∏‡πà‡∏° "‡∏î‡∏π‡πÄ‡∏û‡∏¥‡πà‡∏°‡πÄ‡∏ï‡∏¥‡∏°" ‡πÉ‡∏ô panel ‡∏î‡πâ‡∏≤‡∏ô‡∏Ç‡∏ß‡∏≤')
        else:
            print('  [LOG] ‚ùó ‡πÑ‡∏°‡πà‡πÄ‡∏à‡∏≠ panel ‡∏î‡πâ‡∏≤‡∏ô‡∏Ç‡∏ß‡∏≤ (‡∏ó‡∏±‡πâ‡∏á selector ‡πÉ‡∏´‡∏°‡πà‡πÅ‡∏•‡∏∞‡πÄ‡∏Å‡πà‡∏≤)')
    except Exception as e:
        print(f'  [LOG] ‚ùó Error scroll/click load more in right panel: {e}')
    return False

async def download_image(session, img_url, file_path, downloaded_hashes):
    try:
        async with session.get(img_url, timeout=5) as response:
            if response.status == 200:
                image_data = await response.read()
                image_hash = calculate_image_hash(image_data)
                if image_hash in downloaded_hashes:
                    return False
                file_path = os.path.splitext(file_path)[0] + ".jpg"
                with open(file_path, "wb") as f:
                    f.write(image_data)
                # ‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡∏ß‡πà‡∏≤‡πÑ‡∏ü‡∏•‡πå‡∏ö‡∏±‡∏ô‡∏ó‡∏∂‡∏Å‡∏™‡∏≥‡πÄ‡∏£‡πá‡∏à‡πÅ‡∏•‡∏∞‡∏°‡∏µ‡∏Ç‡∏ô‡∏≤‡∏î‡∏û‡∏≠
                if os.path.exists(file_path) and os.path.getsize(file_path) > 1000:
                    downloaded_hashes.add(image_hash)
                    return True
                else:
                    # ‡∏•‡∏ö‡πÑ‡∏ü‡∏•‡πå‡πÄ‡∏™‡∏µ‡∏¢
                    if os.path.exists(file_path):
                        os.remove(file_path)
                    return False
    except Exception:
        pass
    return False

async def scroll_to_bottom(page):
    previous_height = await page.evaluate("document.body.scrollHeight")
    for _ in range(1):  # scroll 1 ‡∏£‡∏≠‡∏ö‡πÄ‡∏û‡∏∑‡πà‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏°‡πÄ‡∏£‡πá‡∏ß
        await page.evaluate("window.scrollTo(0, document.body.scrollHeight)")
        await asyncio.sleep(0.2)
        new_height = await page.evaluate("document.body.scrollHeight")
        if new_height == previous_height:
            break
        previous_height = new_height

async def scroll_right_panel(page):
    # ‡∏´‡∏≤ div panel ‡∏î‡πâ‡∏≤‡∏ô‡∏Ç‡∏ß‡∏≤ (‡πÄ‡∏ä‡πà‡∏ô class 'hh1Ztf ip4nvd k4o2Hc')
    panel = await page.query_selector('div.hh1Ztf.ip4nvd.k4o2Hc')
    if panel:
        await page.evaluate('(el) => { el.scrollTop = el.scrollHeight }', panel)
        await asyncio.sleep(0.5)

# --- ‡∏•‡∏ö‡∏ü‡∏±‡∏á‡∏Å‡πå‡∏ä‡∏±‡∏ô click_load_more_in_panel ---

async def scrape_images_for_category(category, search_terms, max_images, max_related_depth, session, page):
    category_folder = os.path.join(DATA_FOLDER, category)
    ensure_folder_exists(category_folder)
    downloaded_hashes = set()
    
    # ‡∏Ñ‡∏≥‡∏ô‡∏ß‡∏ì quota ‡πÉ‡∏´‡πâ‡∏Å‡∏£‡∏∞‡∏à‡∏≤‡∏¢‡πÄ‡∏ó‡πà‡∏≤‡πÜ ‡∏Å‡∏±‡∏ô
    quota_per_query = max_images // len(search_terms)
    quotas = [quota_per_query] * len(search_terms)
    # ‡∏Å‡∏£‡∏∞‡∏à‡∏≤‡∏¢‡πÄ‡∏®‡∏©‡πÉ‡∏´‡πâ‡∏Ñ‡∏≥‡∏Ñ‡πâ‡∏ô‡πÅ‡∏£‡∏Å
    remaining = max_images - (quota_per_query * len(search_terms))
    if remaining > 0:
        quotas[0] += remaining
    
    total_downloaded = 0
    category_start_time = time.time()
    
    for query_idx, (query, quota) in enumerate(zip(search_terms, quotas)):
        query_start_time = time.time()
        used_queries = set()
        queue = [(query, 0)]  # (query, depth)
        downloaded_count = 0
        error_reason = None
        max_attempts = 3  # ‡∏û‡∏¢‡∏≤‡∏¢‡∏≤‡∏° 3 ‡∏Ñ‡∏£‡∏±‡πâ‡∏á‡∏ï‡πà‡∏≠‡∏Ñ‡∏≥‡∏Ñ‡πâ‡∏ô
        
        for attempt in range(max_attempts):
            if downloaded_count >= quota:
                break
                
            while queue and downloaded_count < quota:
                current_query, depth = queue.pop(0)
                if current_query in used_queries:
                    continue
                used_queries.add(current_query)
                
                # ‡πÅ‡∏™‡∏î‡∏á progress bar ‡∏Ç‡∏≠‡∏á‡πÅ‡∏ï‡πà‡∏•‡∏∞ query
                print(f"\n[‡∏´‡∏°‡∏ß‡∏î {category}] ‡∏Ñ‡∏≥‡∏Ñ‡πâ‡∏ô: {query} | ‡∏Ñ‡∏≥‡∏Ñ‡πâ‡∏ô‡∏õ‡∏±‡∏à‡∏à‡∏∏‡∏ö‡∏±‡∏ô: {current_query} (depth {depth}) | quota {quota} | ‡∏û‡∏¢‡∏≤‡∏¢‡∏≤‡∏°‡∏Ñ‡∏£‡∏±‡πâ‡∏á‡∏ó‡∏µ‡πà {attempt+1}")
                query_params = urlencode({"q": current_query, "tbm": "isch"})
                search_url = f"https://www.google.com/search?{query_params}"
                await page.goto(search_url)
                await asyncio.sleep(0.2)
                await disable_safesearch(page)
                
                # --- scroll grid ‡∏´‡∏•‡∏±‡∏Å‡∏ã‡πâ‡∏≥ ‡πÜ ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡πÇ‡∏´‡∏•‡∏î‡∏†‡∏≤‡∏û‡πÉ‡∏´‡∏°‡πà ---
                seen_img_count = 0
                max_scroll_rounds = 40  # ‡πÄ‡∏û‡∏¥‡πà‡∏°‡∏à‡∏≥‡∏ô‡∏ß‡∏ô‡∏£‡∏≠‡∏ö scroll
                for scroll_round in range(max_scroll_rounds):
                    await scroll_to_bottom(page)
                    await asyncio.sleep(0.5)
                    try:
                        await page.wait_for_selector('div[data-id="mosaic"]', timeout=3000)
                    except Exception:
                        error_reason = "‡πÑ‡∏°‡πà‡∏û‡∏ö grid ‡∏´‡∏•‡∏±‡∏Å‡∏Ç‡∏≠‡∏á‡∏†‡∏≤‡∏û"
                        break
                    image_elements = await page.query_selector_all('div[data-attrid="images universal"]')
                    if len(image_elements) == seen_img_count:
                        break
                    
                    # ‡πÑ‡∏•‡πà‡∏Ñ‡∏•‡∏¥‡∏Å‡∏†‡∏≤‡∏û‡πÉ‡∏´‡∏°‡πà‡∏ó‡∏µ‡πà‡∏¢‡∏±‡∏á‡πÑ‡∏°‡πà‡πÑ‡∏î‡πâ‡πÇ‡∏´‡∏•‡∏î
                    img_idx = seen_img_count
                    while img_idx < len(image_elements) and downloaded_count < quota:
                        tasks = []
                        batch_size = min(BATCH_SIZE, quota - downloaded_count, len(image_elements) - img_idx)
                        file_name_indices = []
                        for b in range(batch_size):
                            image_element = image_elements[img_idx]
                            img_idx += 1
                            try:
                                await image_element.click()
                                await page.wait_for_selector("img.sFlh5c.FyHeAf.iPVvYb[jsaction]", timeout=5000)
                                img_tag = await page.query_selector("img.sFlh5c.FyHeAf.iPVvYb[jsaction]")
                                if not img_tag:
                                    continue
                                img_url = await img_tag.get_attribute("src")
                                if not img_url or img_url.startswith("data:"):
                                    continue
                                file_name = f"{category}_{query_idx+1}_{downloaded_count + len(tasks) + 1:04d}.jpg"
                                file_path = os.path.join(category_folder, file_name)
                                tasks.append(download_image(session, img_url, file_path, downloaded_hashes))
                                file_name_indices.append(file_name)
                            except Exception:
                                continue
                        if tasks:
                            results = await asyncio.gather(*tasks)
                            for i, success in enumerate(results):
                                if success:
                                    downloaded_count += 1
                                    print_progress_bar(downloaded_count, quota, query)
                    seen_img_count = len(image_elements)
                    if downloaded_count >= quota:
                        break
                
                print()  # ‡∏Ç‡∏∂‡πâ‡∏ô‡∏ö‡∏£‡∏£‡∏ó‡∏±‡∏î‡πÉ‡∏´‡∏°‡πà‡∏´‡∏•‡∏±‡∏á‡∏à‡∏ö progress bar
                
                # ‡∏ñ‡πâ‡∏≤ quota ‡∏¢‡∏±‡∏á‡πÑ‡∏°‡πà‡∏Ñ‡∏£‡∏ö‡∏´‡∏•‡∏±‡∏á scroll grid ‡∏Ñ‡∏£‡∏ö ‚Üí ‡πÑ‡∏õ related search (‡∏´‡∏£‡∏∑‡∏≠‡∏î‡∏π‡πÄ‡∏û‡∏¥‡πà‡∏°‡πÄ‡∏ï‡∏¥‡∏°‡πÉ‡∏ô panel ‡∏Ç‡∏ß‡∏≤)
                if downloaded_count < quota:
                    related = []
                    if depth < max_related_depth:
                        related = await get_related_searches(page)
                        for rel in related:
                            if rel not in used_queries and all(rel != q for q, _ in queue):
                                queue.append((rel, depth + 1))
                    if not related:
                        # ‡∏Ñ‡∏•‡∏¥‡∏Å‡∏†‡∏≤‡∏û‡∏™‡∏∏‡∏î‡∏ó‡πâ‡∏≤‡∏¢‡πÉ‡∏ô grid ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡πÄ‡∏õ‡∏¥‡∏î panel ‡∏Ç‡∏ß‡∏≤
                        if image_elements:
                            try:
                                await image_elements[-1].click()
                                await asyncio.sleep(0.7)
                            except Exception:
                                pass
                        # scroll panel ‡∏Ç‡∏ß‡∏≤ + ‡∏Å‡∏î‡∏î‡∏π‡πÄ‡∏û‡∏¥‡πà‡∏°‡πÄ‡∏ï‡∏¥‡∏°
                        load_more_success = await click_load_more_in_right_panel(page)
                        if load_more_success:
                            continue  # ‡∏Å‡∏•‡∏±‡∏ö‡πÑ‡∏õ scroll grid ‡∏´‡∏•‡∏±‡∏Å‡πÉ‡∏´‡∏°‡πà
                        else:
                            error_reason = "‡πÑ‡∏°‡πà‡∏û‡∏ö related search ‡πÅ‡∏•‡∏∞‡πÑ‡∏°‡πà‡∏°‡∏µ‡∏õ‡∏∏‡πà‡∏°‡∏î‡∏π‡πÄ‡∏û‡∏¥‡πà‡∏°‡πÄ‡∏ï‡∏¥‡∏°‡πÉ‡∏ô panel ‡∏Ç‡∏ß‡∏≤"
                            break
            
            # ‡∏ñ‡πâ‡∏≤‡∏¢‡∏±‡∏á‡πÑ‡∏°‡πà‡∏Ñ‡∏£‡∏ö quota ‡πÅ‡∏•‡∏∞‡∏¢‡∏±‡∏á‡∏°‡∏µ‡∏Ñ‡∏≥‡∏Ñ‡πâ‡∏ô‡∏´‡∏≤‡∏≠‡∏∑‡πà‡∏ô ‡πÉ‡∏´‡πâ‡∏•‡∏≠‡∏á‡∏Ñ‡∏≥‡∏Ñ‡πâ‡∏ô‡∏ñ‡∏±‡∏î‡πÑ‡∏õ
            if downloaded_count < quota and attempt < max_attempts - 1:
                print(f"  [LOG] ‡∏û‡∏¢‡∏≤‡∏¢‡∏≤‡∏°‡∏Ñ‡∏£‡∏±‡πâ‡∏á‡∏ó‡∏µ‡πà {attempt+1} ‡πÑ‡∏°‡πà‡∏Ñ‡∏£‡∏ö quota ({downloaded_count}/{quota}) ‡∏•‡∏≠‡∏á‡∏Ñ‡∏£‡∏±‡πâ‡∏á‡∏ñ‡∏±‡∏î‡πÑ‡∏õ...")
                await asyncio.sleep(1)  # ‡∏£‡∏≠‡∏™‡∏±‡∏Å‡∏Ñ‡∏£‡∏π‡πà‡∏Å‡πà‡∏≠‡∏ô‡∏•‡∏≠‡∏á‡πÉ‡∏´‡∏°‡πà
        
        # ‡∏ô‡∏±‡∏ö‡πÑ‡∏ü‡∏•‡πå‡∏à‡∏£‡∏¥‡∏á‡πÉ‡∏ô‡πÇ‡∏ü‡∏•‡πÄ‡∏î‡∏≠‡∏£‡πå‡πÅ‡∏ó‡∏ô‡∏Å‡∏≤‡∏£‡∏ô‡∏±‡∏ö‡∏à‡∏≤‡∏Å‡∏ï‡∏±‡∏ß‡πÅ‡∏õ‡∏£
        actual_count = count_actual_files_in_folder(category_folder)
        total_downloaded = actual_count
        
        # ‡∏Ñ‡∏≥‡∏ô‡∏ß‡∏ì‡πÄ‡∏ß‡∏•‡∏≤‡∏ó‡∏µ‡πà‡πÉ‡∏ä‡πâ‡πÉ‡∏ô‡πÅ‡∏ï‡πà‡∏•‡∏∞ query
        query_end_time = time.time()
        query_duration = query_end_time - query_start_time
        
        if downloaded_count < quota:
            print(f"\n[‡∏Ñ‡∏≥‡∏Ñ‡πâ‡∏ô: {query}] ‚ö†Ô∏è ‡πÇ‡∏´‡∏•‡∏î‡πÑ‡∏î‡πâ {downloaded_count}/{quota} ‡∏£‡∏π‡∏õ (‡πÑ‡∏°‡πà‡∏Ñ‡∏£‡∏ö quota) | ‡πÉ‡∏ä‡πâ‡πÄ‡∏ß‡∏•‡∏≤ {query_duration:.1f} ‡∏ß‡∏¥‡∏ô‡∏≤‡∏ó‡∏µ")
        else:
            print(f"\n[‡∏Ñ‡∏≥‡∏Ñ‡πâ‡∏ô: {query}] ‚úÖ ‡πÇ‡∏´‡∏•‡∏î‡∏Ñ‡∏£‡∏ö quota ‡πÅ‡∏•‡πâ‡∏ß ({downloaded_count}/{quota}) | ‡πÉ‡∏ä‡πâ‡πÄ‡∏ß‡∏•‡∏≤ {query_duration:.1f} ‡∏ß‡∏¥‡∏ô‡∏≤‡∏ó‡∏µ")
    
    # ‡∏Ñ‡∏≥‡∏ô‡∏ß‡∏ì‡πÄ‡∏ß‡∏•‡∏≤‡∏ó‡∏±‡πâ‡∏á‡∏´‡∏°‡∏î‡∏Ç‡∏≠‡∏á‡∏´‡∏°‡∏ß‡∏î‡∏´‡∏°‡∏π‡πà
    category_end_time = time.time()
    category_duration = category_end_time - category_start_time
    print(f"[‡∏´‡∏°‡∏ß‡∏î {category}] ‡∏î‡∏≤‡∏ß‡∏ô‡πå‡πÇ‡∏´‡∏•‡∏î‡πÄ‡∏™‡∏£‡πá‡∏à‡∏™‡∏¥‡πâ‡∏ô {total_downloaded} ‡∏£‡∏π‡∏õ | ‡πÉ‡∏ä‡πâ‡πÄ‡∏ß‡∏•‡∏≤‡∏ó‡∏±‡πâ‡∏á‡∏´‡∏°‡∏î {category_duration:.1f} ‡∏ß‡∏¥‡∏ô‡∏≤‡∏ó‡∏µ")
    return total_downloaded

async def main():
    print("‡πÄ‡∏£‡∏¥‡πà‡∏°‡∏î‡∏≤‡∏ß‡∏ô‡πå‡πÇ‡∏´‡∏•‡∏î...")
    program_start_time = time.time()
    
    if CLEAR_FOLDER_BEFORE_RUN:
        clear_all_category_images()
    
    total_downloaded = 0
    category_times = {}
    
    async with async_playwright() as p:
        browser = await p.chromium.launch(headless=HEADLESS_BROWSER)
        page = await browser.new_page()
        async with ClientSession(timeout=ClientTimeout(total=TIMEOUT_DURATION)) as session:
            for category, search_terms in CATEGORY_SEARCHES.items():
                print(f"\n==============================\n‡∏´‡∏°‡∏ß‡∏î‡∏´‡∏°‡∏π‡πà: {category}")
                category_start_time = time.time()
                downloaded = await scrape_images_for_category(
                    category,
                    search_terms,
                    MAX_IMAGES_PER_CATEGORY,
                    MAX_RELATED_DEPTH,
                    session,
                    page
                )
                category_end_time = time.time()
                category_duration = category_end_time - category_start_time
                category_times[category] = category_duration
                total_downloaded += downloaded
                print(f"‡πÉ‡∏ä‡πâ‡πÄ‡∏ß‡∏•‡∏≤ {category_duration:.1f} ‡∏ß‡∏¥‡∏ô‡∏≤‡∏ó‡∏µ | ‡πÑ‡∏î‡πâ {downloaded} ‡∏£‡∏π‡∏õ")
        await browser.close()
    
    # ‡∏Ñ‡∏≥‡∏ô‡∏ß‡∏ì‡πÄ‡∏ß‡∏•‡∏≤‡∏ó‡∏±‡πâ‡∏á‡∏´‡∏°‡∏î
    program_end_time = time.time()
    total_duration = program_end_time - program_start_time
    
    print(f"\n" + "="*60)
    print("üìä ‡∏™‡∏£‡∏∏‡∏õ‡∏Å‡∏≤‡∏£‡∏î‡∏≤‡∏ß‡∏ô‡πå‡πÇ‡∏´‡∏•‡∏î")
    print("="*60)
    print(f"üìà ‡∏£‡∏ß‡∏°‡∏ó‡∏±‡πâ‡∏á‡∏´‡∏°‡∏î: {total_downloaded} ‡∏£‡∏π‡∏õ")
    print(f"‚è±Ô∏è  ‡πÄ‡∏ß‡∏•‡∏≤‡∏ó‡∏±‡πâ‡∏á‡∏´‡∏°‡∏î: {total_duration:.1f} ‡∏ß‡∏¥‡∏ô‡∏≤‡∏ó‡∏µ ({total_duration/60:.1f} ‡∏ô‡∏≤‡∏ó‡∏µ)")
    print(f"üöÄ ‡∏Ñ‡∏ß‡∏≤‡∏°‡πÄ‡∏£‡πá‡∏ß‡πÄ‡∏â‡∏•‡∏µ‡πà‡∏¢: {total_downloaded/total_duration:.1f} ‡∏£‡∏π‡∏õ/‡∏ß‡∏¥‡∏ô‡∏≤‡∏ó‡∏µ")
    
    print(f"\nüìã ‡πÄ‡∏ß‡∏•‡∏≤‡πÅ‡∏ï‡πà‡∏•‡∏∞‡∏´‡∏°‡∏ß‡∏î‡∏´‡∏°‡∏π‡πà:")
    for category, duration in category_times.items():
        print(f"  ‚Ä¢ {category:10}: {duration:6.1f} ‡∏ß‡∏¥‡∏ô‡∏≤‡∏ó‡∏µ")
    
    print("="*60)
    
    # ‡∏ó‡∏≥‡∏Ñ‡∏ß‡∏≤‡∏°‡∏™‡∏∞‡∏≠‡∏≤‡∏î‡πÑ‡∏ü‡∏•‡πå‡πÄ‡∏™‡∏µ‡∏¢
    print(f"\nüßπ ‡∏Å‡∏≥‡∏•‡∏±‡∏á‡∏ó‡∏≥‡∏Ñ‡∏ß‡∏≤‡∏°‡∏™‡∏∞‡∏≠‡∏≤‡∏î‡πÑ‡∏ü‡∏•‡πå‡πÄ‡∏™‡∏µ‡∏¢...")
    cleaned_count = clean_corrupted_images()
    if cleaned_count > 0:
        print(f"‚úÖ ‡∏•‡∏ö‡πÑ‡∏ü‡∏•‡πå‡πÄ‡∏™‡∏µ‡∏¢‡πÅ‡∏•‡πâ‡∏ß {cleaned_count} ‡πÑ‡∏ü‡∏•‡πå")
    else:
        print(f"‚úÖ ‡πÑ‡∏°‡πà‡∏û‡∏ö‡πÑ‡∏ü‡∏•‡πå‡πÄ‡∏™‡∏µ‡∏¢")
    
    # ‡∏™‡∏£‡∏∏‡∏õ‡∏à‡∏≥‡∏ô‡∏ß‡∏ô‡∏†‡∏≤‡∏û‡∏™‡∏∏‡∏î‡∏ó‡πâ‡∏≤‡∏¢
    print(f"\nüìä ‡∏™‡∏£‡∏∏‡∏õ‡∏à‡∏≥‡∏ô‡∏ß‡∏ô‡∏†‡∏≤‡∏û‡∏™‡∏∏‡∏î‡∏ó‡πâ‡∏≤‡∏¢:")
    final_summary = get_image_summary()
    total_final = 0
    
    for category, count in final_summary.items():
        print(f"  üìÅ {category:10}: {count:6} ‡∏£‡∏π‡∏õ")
        total_final += count
    
    print(f"  üìà ‡∏£‡∏ß‡∏°‡∏ó‡∏±‡πâ‡∏á‡∏´‡∏°‡∏î: {total_final} ‡∏£‡∏π‡∏õ")
    
    # ‡πÄ‡∏õ‡∏£‡∏µ‡∏¢‡∏ö‡πÄ‡∏ó‡∏µ‡∏¢‡∏ö‡∏Å‡∏±‡∏ö‡πÄ‡∏õ‡πâ‡∏≤‡∏´‡∏°‡∏≤‡∏¢
    target_total = len(CATEGORY_SEARCHES) * MAX_IMAGES_PER_CATEGORY
    success_rate = (total_final / target_total) * 100
    
    print(f"\nüéØ ‡∏ú‡∏•‡∏Å‡∏≤‡∏£‡∏ó‡∏≥‡∏á‡∏≤‡∏ô:")
    print(f"  ‚Ä¢ ‡πÄ‡∏õ‡πâ‡∏≤‡∏´‡∏°‡∏≤‡∏¢: {target_total} ‡∏£‡∏π‡∏õ")
    print(f"  ‚Ä¢ ‡πÑ‡∏î‡πâ‡∏à‡∏£‡∏¥‡∏á: {total_final} ‡∏£‡∏π‡∏õ")
    print(f"  ‚Ä¢ ‡∏≠‡∏±‡∏ï‡∏£‡∏≤‡∏Ñ‡∏ß‡∏≤‡∏°‡∏™‡∏≥‡πÄ‡∏£‡πá‡∏à: {success_rate:.1f}%")
    
    if success_rate >= 95:
        print(f"  üéâ ‡∏¢‡∏≠‡∏î‡πÄ‡∏¢‡∏µ‡πà‡∏¢‡∏°! ‡πÇ‡∏´‡∏•‡∏î‡πÑ‡∏î‡πâ‡πÄ‡∏Å‡∏∑‡∏≠‡∏ö‡∏Ñ‡∏£‡∏ö‡πÄ‡∏õ‡πâ‡∏≤‡∏´‡∏°‡∏≤‡∏¢")
    elif success_rate >= 80:
        print(f"  üëç ‡∏î‡∏µ‡∏°‡∏≤‡∏Å! ‡πÇ‡∏´‡∏•‡∏î‡πÑ‡∏î‡πâ‡∏°‡∏≤‡∏Å‡∏Å‡∏ß‡πà‡∏≤ 80%")
    elif success_rate >= 60:
        print(f"  ‚úÖ ‡∏ú‡πà‡∏≤‡∏ô! ‡πÇ‡∏´‡∏•‡∏î‡πÑ‡∏î‡πâ‡∏°‡∏≤‡∏Å‡∏Å‡∏ß‡πà‡∏≤ 60%")
    else:
        print(f"  ‚ö†Ô∏è  ‡∏Ñ‡∏ß‡∏£‡∏õ‡∏£‡∏±‡∏ö‡∏õ‡∏£‡∏∏‡∏á! ‡πÇ‡∏´‡∏•‡∏î‡πÑ‡∏î‡πâ‡∏ô‡πâ‡∏≠‡∏¢‡∏Å‡∏ß‡πà‡∏≤ 60%")
    
    print("="*60)

if __name__ == "__main__":
    try:
        asyncio.run(main())
    except KeyboardInterrupt:
        print("\n\n‚ö†Ô∏è  ‡∏´‡∏¢‡∏∏‡∏î‡∏Å‡∏≤‡∏£‡∏ó‡∏≥‡∏á‡∏≤‡∏ô‡πÇ‡∏î‡∏¢‡∏ú‡∏π‡πâ‡πÉ‡∏ä‡πâ")
    except Exception as e:
        print(f"\n\n‚ùå ‡πÄ‡∏Å‡∏¥‡∏î‡∏Ç‡πâ‡∏≠‡∏ú‡∏¥‡∏î‡∏û‡∏•‡∏≤‡∏î: {e}")
    finally:
        # ‡∏õ‡∏¥‡∏î event loop ‡∏≠‡∏¢‡πà‡∏≤‡∏á‡∏™‡∏°‡∏ö‡∏π‡∏£‡∏ì‡πå
        try:
            loop = asyncio.get_event_loop()
            if not loop.is_closed():
                loop.close()
        except:
            pass